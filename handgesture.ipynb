{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', 'leapGestRecog']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "print(os.listdir(\"C:/Users/HP/OneDrive/Desktop/prodigy/leapGestRecog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different classes that exist in this dataset are:\n",
      "{'10_down', '03_fist', '04_fist_moved', '09_c', '01_palm', '07_ok', '05_thumb', '08_palm_moved', '02_l', '06_index'}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import IPython.display\n",
    "path='C:/Users/HP/OneDrive/Desktop/prodigy/leapGestRecog'\n",
    "folders=os.listdir(path)\n",
    "folders=set(folders)\n",
    "\n",
    "#import codecs\n",
    "#import json\n",
    "\n",
    "\n",
    "different_classes=os.listdir(path+'/'+'00')\n",
    "different_classes=set(different_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"The different classes that exist in this dataset are:\")\n",
    "print(different_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfolders\u001b[49m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***\u001b[39m\u001b[38;5;124m'\u001b[39m,i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     subject\u001b[38;5;241m=\u001b[39mpath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mi\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folders' is not defined"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "z=[]\n",
    "y=[]#converting the image to black and white\n",
    "threshold=200\n",
    "import cv2\n",
    "\n",
    "\n",
    "for i in folders:\n",
    "    print('***',i,'***')\n",
    "    subject=path+'/'+i\n",
    "    subdir=os.listdir(subject)\n",
    "    subdir=set(subdir)\n",
    "    for j in subdir:\n",
    "        #print(j)\n",
    "        images=os.listdir(subject+'/'+j)\n",
    "        for k in images:\n",
    "            results=dict()\n",
    "            results['y']=j.split('_')[0]\n",
    "            img = cv2.imread(subject+'/'+j+'/'+k,0)\n",
    "            img=cv2.resize(img,(int(160),int(60)))\n",
    "            \n",
    "            ret, imgf = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            imgD=np.asarray(img,dtype=np.float64)\n",
    "            z.append(imgD)\n",
    "            imgf=np.asarray(imgf,dtype=np.float64)\n",
    "            x.append(imgf)\n",
    "            y.append(int(j.split('_')[0]))\n",
    "            results['x']=imgf\n",
    "l = []\n",
    "list_names = []\n",
    "for i in range(10):\n",
    "    l.append(0)\n",
    "for i in range(len(x)):\n",
    "    if(l[y[i] - 1] == 0):\n",
    "        l[y[i] - 1] = i\n",
    "        if(len(np.unique(l)) == 10):\n",
    "            break\n",
    "for i in range(len(l)):\n",
    "    %matplotlib inline\n",
    "    print(\"Class Label: \" + str(i + 1))\n",
    "    plt.imshow(np.asarray(z[l[i]]), cmap  =cm.gray)\n",
    "    plt.show()\n",
    "    plt.imshow(np.asarray(x[l[i]]), cmap = cm.gray)     \n",
    "    plt.show()\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "y = y.reshape(len(x), 1)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(max(y),min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x.reshape((len(x), 60, 160, 1))\n",
    "\n",
    "x_data/=255\n",
    "x_data=list(x_data)\n",
    "for i in range(len(x_data)):\n",
    "    x_data[i]=x_data[i].flatten()\n",
    "len(x_data)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "x_data=np.array(x_data)\n",
    "print(\"Before PCA\",x_data.shape)\n",
    "x_data=pca.fit_transform(x_data)\n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)  \n",
    "\n",
    "print('___________________')\n",
    "print(\"After PCA\",x_data.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_further,y_train,y_further = train_test_split(x_data,y,test_size = 0.2)\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "#The idea behind StandardScaler is that it will transform your data\n",
    "#such that its distribution will have a mean value 0 and standard deviation of 1.\n",
    "scaler.fit(x_train)\n",
    "\n",
    "X_train = scaler.transform(x_train)  \n",
    "X_test = scaler.transform(x_further) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd= SGDClassifier(loss='log',shuffle=True,random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test) \n",
    "y_train_score_sgd=sgd.predict(X_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_further, y_pred_sgd, normalize=True, sample_weight=None)\n",
    "acc_train = accuracy_score(y_train, y_train_score_sgd, normalize=True, sample_weight=None)\n",
    "print(\"accuracy of the model is:\\nTest \", acc)\n",
    "print('Train ',acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred_dt=clf.predict(X_test)\n",
    "y_train_score_dt=clf.predict(X_train)\n",
    "print(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_dt, normalize=True, sample_weight=None))\n",
    "print('Train',accuracy_score(y_train, y_train_score_dt, normalize=True, sample_weight=None))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rft = RandomForestClassifier(n_estimators=100, max_depth=15,random_state=0)\n",
    "clf_rft = clf_rft.fit(X_train, y_train)\n",
    "y_pred_rft=clf_rft.predict(X_test)\n",
    "y_train_score_rft=clf_rft.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_rft, normalize=True, sample_weight=None))\n",
    "print('Train',accuracy_score(y_train, y_train_score_rft, normalize=True, sample_weight=None))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(solver = 'newton-cg')\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred_logistic=logistic.predict(X_test)\n",
    "y_train_score_logistic=logistic.predict(X_train)\n",
    "print(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_logistic, normalize=True, sample_weight=None))\n",
    "print('Train',accuracy_score(y_train, y_train_score_logistic, normalize=True, sample_weight=None))\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb=gnb.predict(X_test)\n",
    "y_train_score_gnb=gnb.predict(X_train)\n",
    "print(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_gnb, normalize=True, sample_weight=None))\n",
    "print('Train',accuracy_score(y_train, y_train_score_gnb, normalize=True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdc_model= GradientBoostingClassifier(learning_rate=0.01,random_state=41)\n",
    "gdc_model.fit(x_train, y_train)\n",
    "y_pred_gdc=gdc_model.predict(X_test)\n",
    "y_train_score_gdc=gdc_model.predict(X_train)\n",
    "print(\"accuracy of the model is:\\nTest \", accuracy_score(y_further, y_pred_gdc, normalize=True, sample_weight=None))\n",
    "print('Train',accuracy_score(y_train, y_train_score_gdc, normalize=True, sample_weight=None))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
